{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-FastText.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parsa-abbasi/Sentiment-Analysis/blob/master/SentiPers/BinaryClassifier/NN/GoogleColab/DataAugmentation/SimilarWords/LSTM_FastTextEmb_RN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QthdEc8Cp5Nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get FastText Persian"
      ]
    },
    {
      "metadata": {
        "id": "4wCOcr1ao1VX",
        "colab_type": "code",
        "outputId": "a6366980-1f78-4540-ad50-70d4471e2f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.fa.vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-17 06:48:37--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.fa.vec\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:16a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1105157170 (1.0G) [binary/octet-stream]\n",
            "Saving to: ‘wiki.fa.vec’\n",
            "\n",
            "wiki.fa.vec         100%[===================>]   1.03G  45.5MB/s    in 21s     \n",
            "\n",
            "2019-04-17 06:48:58 (49.6 MB/s) - ‘wiki.fa.vec’ saved [1105157170/1105157170]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0yHgWvqWBAqS",
        "colab_type": "code",
        "outputId": "c380e53a-ef0d-4c58-d661-44b8e6389bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install hazm\n",
        "!pip install stopwords_guilannlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hazm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/13/5a7074bc11d20dbbb46239349ac3f85f7edc148b4cf68e9b8c2f8263830c/hazm-0.7.0-py3-none-any.whl (316kB)\n",
            "\u001b[K    100% |████████████████████████████████| 317kB 32.0MB/s \n",
            "\u001b[?25hCollecting nltk==3.3 (from hazm)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 18.4MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1; platform_system != \"Windows\" (from hazm)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/0f/1c9b49bb49821b5856a64ea6fac8d96a619b9f291d1f06999ea98a32c89c/libwapiti-0.2.1.tar.gz (233kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.3->hazm) (1.11.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/66/15/54/4510dce8bb958b1cdd2c47425cbd1e1eecc0480ac9bb1fb9ab\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n",
            "Collecting stopwords_guilannlp\n",
            "  Downloading https://files.pythonhosted.org/packages/44/bc/a01c003b59a91187e89d11e73e8bb2834bb9ae6b36fe576a4b617c90bd23/stopwords_guilannlp-13.2019.3.5-py3-none-any.whl\n",
            "Installing collected packages: stopwords-guilannlp\n",
            "Successfully installed stopwords-guilannlp-13.2019.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qHENRyUpp-fb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "DyJ0hqR8nku1",
        "colab_type": "code",
        "outputId": "bc96c3e3-9293-4064-cd84-86c526fe0069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.layers import CuDNNLSTM\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.utils import plot_model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import KeyedVectors\n",
        "import codecs\n",
        "from stopwords_guilannlp import stopwords_output\n",
        "from hazm import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "56Zm6edfuwXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# File uploader"
      ]
    },
    {
      "metadata": {
        "id": "VvTYlRzbuwcd",
        "colab_type": "code",
        "outputId": "c8c4b176-b9bf-4f57-d9e7-6374b347f58f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-61217e62-71e5-40a4-a2d7-e29b35bac111\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-61217e62-71e5-40a4-a2d7-e29b35bac111\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving x_test.csv to x_test (1).csv\n",
            "Saving x_train.csv to x_train (1).csv\n",
            "Saving y_test.csv to y_test (1).csv\n",
            "Saving y_train.csv to y_train (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6FbuK-Gmupe2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Import Dataset"
      ]
    },
    {
      "metadata": {
        "id": "RXEXLFZoupUr",
        "colab_type": "code",
        "outputId": "a870b29a-cf5a-40c8-db36-79b85298e7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "x_train = pd.Series.from_csv('x_train (1).csv', sep='\\t')\n",
        "x_test = pd.Series.from_csv('x_test (1).csv', sep='\\t')\n",
        "y_train = pd.Series.from_csv('y_train (1).csv', sep='\\t', header=0)\n",
        "y_test = pd.Series.from_csv('y_test (1).csv', sep='\\t', header=0)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:3727: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
            "  infer_datetime_format=infer_datetime_format)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HMIMBSUa97Zm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.iloc[1:, ]\n",
        "x_test = x_test.iloc[1:, ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MATiU_eixlin",
        "colab_type": "code",
        "outputId": "32a857ab-0194-4491-ae54-9f3b0d90868b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('y_test shape: ', y_test.shape)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (11121,)\n",
            "x_test shape:  (1854,)\n",
            "y_train shape:  (11121,)\n",
            "y_test shape:  (1854,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nL5mDIUfzjyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.asarray(x_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xEQgbeiEklc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17dccaf7-b629-49b9-ed2d-a4047e37a13f"
      },
      "cell_type": "code",
      "source": [
        "# See the data number of each category \n",
        "from collections import Counter\n",
        "cnt = Counter(y_train)\n",
        "cnt = dict(cnt)\n",
        "print(cnt)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 3246, 2: 1976, 0: 4817, -1: 1026, -2: 56}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3JCRrbCjkb3",
        "colab_type": "code",
        "outputId": "96509a20-d3ae-498f-e7d3-4fe50f558f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "binary_y_train = []\n",
        "binary_y_test = []\n",
        "binary_x_train = []\n",
        "binary_x_test = []\n",
        "for i, y in enumerate(y_train):\n",
        "  if y != 0:\n",
        "    if y > 0:\n",
        "      binary_y_train.append(1)\n",
        "      binary_x_train.append(x_train[i])\n",
        "    else:\n",
        "      binary_y_train.append(0)\n",
        "      binary_x_train.append(x_train[i])\n",
        "      \n",
        "for i, y in enumerate(y_test):\n",
        "  if y != 0:\n",
        "    if y > 0:\n",
        "      binary_y_test.append(1)\n",
        "      binary_x_test.append(x_test[i])\n",
        "    else:\n",
        "      binary_y_test.append(0)\n",
        "      binary_x_test.append(x_test[i])\n",
        "      \n",
        "\n",
        "x_train = np.asarray(binary_x_train)\n",
        "x_test = np.asarray(binary_x_test)\n",
        "y_train = np.asarray(binary_y_train)\n",
        "y_test = np.asarray(binary_y_test)\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)\n",
        "print('y_train shape: ', y_train.shape)\n",
        "print('y_test shape: ', y_test.shape)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape:  (6304,)\n",
            "x_test shape:  (1111,)\n",
            "y_train shape:  (6304,)\n",
            "y_test shape:  (1111,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t2oX_KNK4t0p",
        "colab_type": "code",
        "outputId": "03f12d1c-9f6e-4493-b60b-a007208098fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# See the data number of each category \n",
        "from collections import Counter\n",
        "cnt = Counter(y_train)\n",
        "cnt = dict(cnt)\n",
        "print(cnt)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 5222, 0: 1082}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S-YylKUoqElV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Make FastText Model"
      ]
    },
    {
      "metadata": {
        "id": "1F_olE5An-5I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_FILE = 'wiki.fa.vec'\n",
        "\n",
        "def import_with_gensim(file_address):\n",
        "    # Creating the model\n",
        "    ft_model = KeyedVectors.load_word2vec_format(file_address)\n",
        "    # Getting the tokens\n",
        "    ft_words = []\n",
        "    for ft_word in ft_model.vocab:\n",
        "        ft_words.append(ft_word)\n",
        "\n",
        "    return ft_model, ft_words\n",
        "  \n",
        "model, words = import_with_gensim(EMBEDDING_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WbXOKymz-OS1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_size = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lraPVp4ptF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We get the mean and standard deviation of the embedding weights so that we could maintain the\n",
        "# same statistics for the rest of our own random generated weights.\\\n",
        "embedding_list = list()\n",
        "for w in words:\n",
        "    embedding_list.append(model[w])\n",
        "\n",
        "all_embedding = np.stack(embedding_list)\n",
        "emb_mean, emb_std = all_embedding.mean(), all_embedding.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aCPR-DfhyUWi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "puncs = ['،', '.', ',', ':', ';', '\"']\n",
        "normalizer = Normalizer()\n",
        "lemmatizer = Lemmatizer()\n",
        "\n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "    doc = normalizer.normalize(doc) # Normalize document using Hazm Normalizer\n",
        "    tokenized = word_tokenize(doc)  # Tokenize text\n",
        "    tokens = []\n",
        "    for t in tokenized:\n",
        "      temp = t\n",
        "      for p in puncs:\n",
        "        temp = temp.replace(p, '')\n",
        "      tokens.append(temp)\n",
        "    # tokens = [w for w in tokens if not w in stop_set]    # Remove stop words\n",
        "    tokens = [w for w in tokens if not len(w) <= 1]\n",
        "    tokens = [w for w in tokens if not w.isdigit()]\n",
        "    # tokens = [lemmatizer.lemmatize(w) for w in tokens] # Lemmatize sentence words using Hazm Lemmatizer\n",
        "    tokens = ' '.join(tokens)\n",
        "    return tokens\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eaz_5RG90E8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_docs = np.empty_like(x_train)\n",
        "for index, document in enumerate(x_train):\n",
        "    train_docs[index] = clean_doc(document)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXOfMkE1yMOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = 2500\n",
        "\n",
        "# create the tokenizer\n",
        "tokenizer = Tokenizer(num_words=num_words)\n",
        "\n",
        "# fit the tokenizer on the documents\n",
        "tokenizer.fit_on_texts(train_docs)\n",
        "\n",
        "# sequence encode\n",
        "encoded_docs = tokenizer.texts_to_sequences(train_docs)\n",
        "\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in train_docs])\n",
        "x_train_padded = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQ_6Su9L16J9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test_docs = np.empty_like(x_test)\n",
        "for index, document in enumerate(x_test):\n",
        "    test_docs[index] = clean_doc(document)\n",
        "\n",
        "# define vocabulary size (largest integer value)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZnIkLd4rUrb",
        "colab_type": "code",
        "outputId": "c3541146-fe9c-4b1a-909d-7d7b926c990e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# We are going to set the embedding size to the pre-trained dimension as we are replicating it\n",
        "nb_words = len(tokenizer.word_index)\n",
        "\n",
        "# the size will be Number of Words in Vocab X Embedding Size\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "\n",
        "# With the newly created embedding matrix, we'll fill it up with the words that we have in both\n",
        "# our own dictionary and loaded pre-trained embedding.\n",
        "embeddedCount = 0\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    i -= 1\n",
        "    # then we see if this word is in glove's dictionary, if yes, get the corresponding weights\n",
        "    if word in model.vocab:\n",
        "        embedding_vector = model[word]\n",
        "        # and store inside the embedding matrix that we will train later on.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        embeddedCount += 1\n",
        "    else:   # Unknown words\n",
        "        embedding_vector = model['subdivision_name']\n",
        "        # and store inside the embedding matrix that we will train later on.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        embeddedCount += 1\n",
        "\n",
        "print('total embedded:', embeddedCount, 'common words')\n",
        "print('Embedding matrix shape:', embedding_matrix.shape)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total embedded: 7144 common words\n",
            "Embedding matrix shape: (7144, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o8NcUFxQpN1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_docs = tokenizer.texts_to_sequences(test_docs)\n",
        "x_test_padded = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UGzX4V3J2U9F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "metadata": {
        "id": "MadF-98Rufk-",
        "colab_type": "code",
        "outputId": "5d00f817-9891-4e40-9073-94c19cb6349d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "inp = Input(shape=(max_length, ))\n",
        "x = Embedding(len(tokenizer.word_index), embedding_matrix.shape[1], weights=[embedding_matrix], trainable=False)(inp)\n",
        "x = Bidirectional(CuDNNLSTM(300, return_sequences=True, name='lstm_layer'))(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(300, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "# optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
        "# optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
        "# optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "hist = model.fit(x_train_padded, y_train, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "loss, acc = model.evaluate(x_test_padded, y_test, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 297)               0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 297, 300)          2143200   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 297, 600)          1444800   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 300)               180300    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 301       \n",
            "=================================================================\n",
            "Total params: 3,768,601\n",
            "Trainable params: 1,625,401\n",
            "Non-trainable params: 2,143,200\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "6304/6304 [==============================] - 12s 2ms/step - loss: 0.4345 - acc: 0.8309\n",
            "Epoch 2/5\n",
            "6304/6304 [==============================] - 11s 2ms/step - loss: 0.2881 - acc: 0.8794\n",
            "Epoch 3/5\n",
            "6304/6304 [==============================] - 11s 2ms/step - loss: 0.1146 - acc: 0.9581\n",
            "Epoch 4/5\n",
            "6304/6304 [==============================] - 12s 2ms/step - loss: 0.0328 - acc: 0.9916\n",
            "Epoch 5/5\n",
            "6304/6304 [==============================] - 12s 2ms/step - loss: 0.0213 - acc: 0.9930\n",
            "Test Accuracy: 86.228623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hiqdfnXMKlsZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
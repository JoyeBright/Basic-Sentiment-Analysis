{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customized-CustomizedEmb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoyeBright/Sentiment-Analysis/blob/master/SentiPers/Classifier/NN/GoogleColab/Customized_CustomizedEmb/Customized_CustomizedEmb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4GBO4nPNe2Cf",
        "colab_type": "code",
        "outputId": "19fc9c28-c0fd-4aa4-dfcb-4c6848db4cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install hazm\n",
        "!pip install stopwords_guilannlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.6/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from libwapiti>=0.2.1; platform_system != \"Windows\"->hazm) (1.11.0)\n",
            "Collecting stopwords_guilannlp\n",
            "  Downloading https://files.pythonhosted.org/packages/44/bc/a01c003b59a91187e89d11e73e8bb2834bb9ae6b36fe576a4b617c90bd23/stopwords_guilannlp-13.2019.3.5-py3-none-any.whl\n",
            "Installing collected packages: stopwords-guilannlp\n",
            "Successfully installed stopwords-guilannlp-13.2019.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iin0WUrwegMq",
        "colab_type": "code",
        "outputId": "9d90df2d-39ae-4a92-d348-b7f55ae04072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.backend import eval\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import scale\n",
        "import io"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iHOmP3qNf8xx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import dataset files"
      ]
    },
    {
      "metadata": {
        "id": "ckkhvObMfIB-",
        "colab_type": "code",
        "outputId": "b7376862-1215-44ac-8795-42fa801b14fb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bc595b80-7ced-4fff-b930-e683cb444cfd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bc595b80-7ced-4fff-b930-e683cb444cfd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_vecs_w2v.csv to test_vecs_w2v.csv\n",
            "Saving train_vecs_w2v.csv to train_vecs_w2v.csv\n",
            "Saving y_test.csv to y_test.csv\n",
            "Saving y_train.csv to y_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G8rPBQXvx0Cy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conversion"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "7cbc7267-95cc-4160-bedb-003ec35d80ec",
        "id": "Nhbvxen7-z5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = pd.Series.from_csv(\"y_train.csv\", sep=\"\\t\", header=0)\n",
        "y_test = pd.Series.from_csv(\"y_test.csv\", sep=\"\\t\", header=0)\n",
        "test_vecs_w2v = pd.read_csv(\"test_vecs_w2v.csv\", sep=\"\\t\")\n",
        "train_vecs_w2v = pd.read_csv(\"train_vecs_w2v.csv\", sep=\"\\t\")\n",
        "\n",
        "\n",
        "test_vecs_w2v = test_vecs_w2v.iloc[:, 1:]\n",
        "train_vecs_w2v = train_vecs_w2v.iloc[:, 1:]\n",
        "\n",
        "\n",
        "test_vecs_w2v = test_vecs_w2v.values\n",
        "train_vecs_w2v = train_vecs_w2v.values\n",
        "\n",
        "# print(y_train[0])\n",
        "# print(train_vecs_w2v[0])\n",
        "\n",
        "# print(y_train.shape)\n",
        "# print(y_test.shape)\n",
        "# print(test_vecs_w2v.shape)\n",
        "# print(train_vecs_w2v.shape)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:2890: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
            "  infer_datetime_format=infer_datetime_format)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ghT7dh1SL-6u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Computation Environment"
      ]
    },
    {
      "metadata": {
        "id": "pl4mWB9xMKNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ea4014e7-32a9-481b-fad3-0596f1ddf949"
      },
      "cell_type": "code",
      "source": [
        "# CPU\n",
        "!lscpu |grep 'Model name'\n",
        "\n",
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "\n",
        "#no.of threads each core is having\n",
        "!lscpu | grep 'Thread(s) per core'\n",
        "\n",
        "#memory that we can use\n",
        "!cat /proc/meminfo | grep 'MemAvailable'\n",
        "\n",
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at 2.3GHz\n",
        "!lscpu | grep \"MHz\"\n",
        "\n",
        "#GPU count and name\n",
        "!nvidia-smi -L\n",
        "\n",
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Socket(s):           1\n",
            "Core(s) per socket:  1\n",
            "Thread(s) per core:  2\n",
            "MemAvailable:   12156288 kB\n",
            "CPU MHz:             2300.000\n",
            "GPU 0: Tesla K80 (UUID: GPU-0792bc69-8f1f-2163-d58a-75cacc7762e5)\n",
            "Thu Jan 17 05:14:21 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    72W / 149W |    170MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7dccxoqTt5T7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Customized NN Model Using Customized Word Embedding"
      ]
    },
    {
      "metadata": {
        "id": "OZUC4gSguFDs",
        "colab_type": "code",
        "outputId": "31bcbb0d-216d-4ae1-cb1a-0a0ebeb1a4a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14110
        }
      },
      "cell_type": "code",
      "source": [
        "# Corpus has categorical value as its output so making categorical output is necessary\n",
        "categorical_y_train = to_categorical(y_train, 5)\n",
        "categorical_y_test = to_categorical(y_test, 5)\n",
        "\n",
        "print(categorical_y_train.shape)\n",
        "print(categorical_y_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(300, activation='relu', input_dim=100))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=300)\n",
        "print('Train ...')\n",
        "print('Learning Rate:',model.optimizer.lr)\n",
        "model.fit(train_vecs_w2v, categorical_y_train,\n",
        "          validation_data=(test_vecs_w2v, categorical_y_test),\n",
        "          epochs=1000, batch_size=5561, callbacks=[early_stopping_monitor], verbose=2)\n",
        "score = model.evaluate(test_vecs_w2v, categorical_y_test)\n",
        "plot_model(model, show_shapes=True, to_file='CustomizedNN-CustomizedEmb.png')\n",
        "print(score[1])\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5561, 5)\n",
            "(1854, 5)\n",
            "Train ...\n",
            "Learning Rate: <tf.Variable 'Adam_16/lr:0' shape=() dtype=float32_ref>\n",
            "Train on 5561 samples, validate on 1854 samples\n",
            "Epoch 1/1000\n",
            " - 2s - loss: 1.6524 - acc: 0.0423 - val_loss: 1.5447 - val_acc: 0.4234\n",
            "Epoch 2/1000\n",
            " - 0s - loss: 1.5486 - acc: 0.4256 - val_loss: 1.4694 - val_acc: 0.4234\n",
            "Epoch 3/1000\n",
            " - 0s - loss: 1.4668 - acc: 0.4256 - val_loss: 1.3952 - val_acc: 0.4234\n",
            "Epoch 4/1000\n",
            " - 0s - loss: 1.3898 - acc: 0.4256 - val_loss: 1.3371 - val_acc: 0.4234\n",
            "Epoch 5/1000\n",
            " - 0s - loss: 1.3302 - acc: 0.4256 - val_loss: 1.3204 - val_acc: 0.4234\n",
            "Epoch 6/1000\n",
            " - 0s - loss: 1.3156 - acc: 0.4256 - val_loss: 1.3181 - val_acc: 0.4234\n",
            "Epoch 7/1000\n",
            " - 0s - loss: 1.3126 - acc: 0.4256 - val_loss: 1.3102 - val_acc: 0.4234\n",
            "Epoch 8/1000\n",
            " - 0s - loss: 1.2973 - acc: 0.4256 - val_loss: 1.3110 - val_acc: 0.4234\n",
            "Epoch 9/1000\n",
            " - 0s - loss: 1.2893 - acc: 0.4256 - val_loss: 1.3307 - val_acc: 0.4234\n",
            "Epoch 10/1000\n",
            " - 0s - loss: 1.3006 - acc: 0.4256 - val_loss: 1.3324 - val_acc: 0.4234\n",
            "Epoch 11/1000\n",
            " - 0s - loss: 1.3011 - acc: 0.4256 - val_loss: 1.3182 - val_acc: 0.4234\n",
            "Epoch 12/1000\n",
            " - 0s - loss: 1.2903 - acc: 0.4256 - val_loss: 1.3149 - val_acc: 0.4234\n",
            "Epoch 13/1000\n",
            " - 0s - loss: 1.2899 - acc: 0.4256 - val_loss: 1.3173 - val_acc: 0.4234\n",
            "Epoch 14/1000\n",
            " - 0s - loss: 1.2937 - acc: 0.4256 - val_loss: 1.3135 - val_acc: 0.4234\n",
            "Epoch 15/1000\n",
            " - 0s - loss: 1.2873 - acc: 0.4256 - val_loss: 1.3053 - val_acc: 0.4234\n",
            "Epoch 16/1000\n",
            " - 0s - loss: 1.2794 - acc: 0.4256 - val_loss: 1.3027 - val_acc: 0.4234\n",
            "Epoch 17/1000\n",
            " - 0s - loss: 1.2769 - acc: 0.4256 - val_loss: 1.3038 - val_acc: 0.4234\n",
            "Epoch 18/1000\n",
            " - 0s - loss: 1.2795 - acc: 0.4256 - val_loss: 1.3005 - val_acc: 0.4234\n",
            "Epoch 19/1000\n",
            " - 0s - loss: 1.2763 - acc: 0.4256 - val_loss: 1.2933 - val_acc: 0.4234\n",
            "Epoch 20/1000\n",
            " - 0s - loss: 1.2726 - acc: 0.4256 - val_loss: 1.2870 - val_acc: 0.4234\n",
            "Epoch 21/1000\n",
            " - 0s - loss: 1.2671 - acc: 0.4256 - val_loss: 1.2831 - val_acc: 0.4234\n",
            "Epoch 22/1000\n",
            " - 0s - loss: 1.2666 - acc: 0.4256 - val_loss: 1.2797 - val_acc: 0.4234\n",
            "Epoch 23/1000\n",
            " - 0s - loss: 1.2647 - acc: 0.4256 - val_loss: 1.2760 - val_acc: 0.4234\n",
            "Epoch 24/1000\n",
            " - 0s - loss: 1.2619 - acc: 0.4256 - val_loss: 1.2721 - val_acc: 0.4234\n",
            "Epoch 25/1000\n",
            " - 0s - loss: 1.2573 - acc: 0.4256 - val_loss: 1.2690 - val_acc: 0.4234\n",
            "Epoch 26/1000\n",
            " - 0s - loss: 1.2524 - acc: 0.4256 - val_loss: 1.2665 - val_acc: 0.4234\n",
            "Epoch 27/1000\n",
            " - 0s - loss: 1.2505 - acc: 0.4256 - val_loss: 1.2636 - val_acc: 0.4234\n",
            "Epoch 28/1000\n",
            " - 0s - loss: 1.2467 - acc: 0.4256 - val_loss: 1.2600 - val_acc: 0.4234\n",
            "Epoch 29/1000\n",
            " - 0s - loss: 1.2437 - acc: 0.4256 - val_loss: 1.2557 - val_acc: 0.4234\n",
            "Epoch 30/1000\n",
            " - 0s - loss: 1.2393 - acc: 0.4256 - val_loss: 1.2511 - val_acc: 0.4234\n",
            "Epoch 31/1000\n",
            " - 0s - loss: 1.2337 - acc: 0.4256 - val_loss: 1.2474 - val_acc: 0.4234\n",
            "Epoch 32/1000\n",
            " - 0s - loss: 1.2325 - acc: 0.4256 - val_loss: 1.2420 - val_acc: 0.4234\n",
            "Epoch 33/1000\n",
            " - 0s - loss: 1.2275 - acc: 0.4256 - val_loss: 1.2370 - val_acc: 0.4234\n",
            "Epoch 34/1000\n",
            " - 0s - loss: 1.2245 - acc: 0.4256 - val_loss: 1.2337 - val_acc: 0.4234\n",
            "Epoch 35/1000\n",
            " - 0s - loss: 1.2218 - acc: 0.4256 - val_loss: 1.2310 - val_acc: 0.4234\n",
            "Epoch 36/1000\n",
            " - 0s - loss: 1.2132 - acc: 0.4256 - val_loss: 1.2285 - val_acc: 0.4272\n",
            "Epoch 37/1000\n",
            " - 0s - loss: 1.2120 - acc: 0.4258 - val_loss: 1.2256 - val_acc: 0.4293\n",
            "Epoch 38/1000\n",
            " - 0s - loss: 1.2067 - acc: 0.4283 - val_loss: 1.2286 - val_acc: 0.4380\n",
            "Epoch 39/1000\n",
            " - 0s - loss: 1.2123 - acc: 0.4314 - val_loss: 1.2220 - val_acc: 0.4423\n",
            "Epoch 40/1000\n",
            " - 0s - loss: 1.2065 - acc: 0.4343 - val_loss: 1.2209 - val_acc: 0.4439\n",
            "Epoch 41/1000\n",
            " - 0s - loss: 1.2012 - acc: 0.4341 - val_loss: 1.2213 - val_acc: 0.4444\n",
            "Epoch 42/1000\n",
            " - 0s - loss: 1.1978 - acc: 0.4364 - val_loss: 1.2173 - val_acc: 0.4482\n",
            "Epoch 43/1000\n",
            " - 0s - loss: 1.1953 - acc: 0.4413 - val_loss: 1.2153 - val_acc: 0.4504\n",
            "Epoch 44/1000\n",
            " - 0s - loss: 1.1922 - acc: 0.4416 - val_loss: 1.2178 - val_acc: 0.4488\n",
            "Epoch 45/1000\n",
            " - 0s - loss: 1.1931 - acc: 0.4389 - val_loss: 1.2101 - val_acc: 0.4558\n",
            "Epoch 46/1000\n",
            " - 0s - loss: 1.1891 - acc: 0.4460 - val_loss: 1.2098 - val_acc: 0.4585\n",
            "Epoch 47/1000\n",
            " - 0s - loss: 1.1868 - acc: 0.4487 - val_loss: 1.2106 - val_acc: 0.4649\n",
            "Epoch 48/1000\n",
            " - 0s - loss: 1.1853 - acc: 0.4533 - val_loss: 1.2056 - val_acc: 0.4649\n",
            "Epoch 49/1000\n",
            " - 0s - loss: 1.1837 - acc: 0.4553 - val_loss: 1.2057 - val_acc: 0.4639\n",
            "Epoch 50/1000\n",
            " - 0s - loss: 1.1825 - acc: 0.4575 - val_loss: 1.1980 - val_acc: 0.4671\n",
            "Epoch 51/1000\n",
            " - 0s - loss: 1.1751 - acc: 0.4636 - val_loss: 1.2029 - val_acc: 0.4671\n",
            "Epoch 52/1000\n",
            " - 0s - loss: 1.1772 - acc: 0.4647 - val_loss: 1.1931 - val_acc: 0.4649\n",
            "Epoch 53/1000\n",
            " - 0s - loss: 1.1705 - acc: 0.4668 - val_loss: 1.1904 - val_acc: 0.4790\n",
            "Epoch 54/1000\n",
            " - 0s - loss: 1.1725 - acc: 0.4776 - val_loss: 1.1882 - val_acc: 0.4725\n",
            "Epoch 55/1000\n",
            " - 0s - loss: 1.1644 - acc: 0.4755 - val_loss: 1.1915 - val_acc: 0.4666\n",
            "Epoch 56/1000\n",
            " - 0s - loss: 1.1625 - acc: 0.4738 - val_loss: 1.1779 - val_acc: 0.4908\n",
            "Epoch 57/1000\n",
            " - 0s - loss: 1.1590 - acc: 0.4850 - val_loss: 1.1776 - val_acc: 0.4844\n",
            "Epoch 58/1000\n",
            " - 0s - loss: 1.1520 - acc: 0.4902 - val_loss: 1.1752 - val_acc: 0.4946\n",
            "Epoch 59/1000\n",
            " - 0s - loss: 1.1474 - acc: 0.4951 - val_loss: 1.1660 - val_acc: 0.5016\n",
            "Epoch 60/1000\n",
            " - 0s - loss: 1.1418 - acc: 0.5024 - val_loss: 1.1694 - val_acc: 0.4924\n",
            "Epoch 61/1000\n",
            " - 0s - loss: 1.1370 - acc: 0.5012 - val_loss: 1.1580 - val_acc: 0.5027\n",
            "Epoch 62/1000\n",
            " - 0s - loss: 1.1243 - acc: 0.5082 - val_loss: 1.1552 - val_acc: 0.5070\n",
            "Epoch 63/1000\n",
            " - 0s - loss: 1.1215 - acc: 0.5145 - val_loss: 1.1556 - val_acc: 0.5011\n",
            "Epoch 64/1000\n",
            " - 0s - loss: 1.1251 - acc: 0.5112 - val_loss: 1.1504 - val_acc: 0.5124\n",
            "Epoch 65/1000\n",
            " - 0s - loss: 1.1153 - acc: 0.5206 - val_loss: 1.1649 - val_acc: 0.5011\n",
            "Epoch 66/1000\n",
            " - 0s - loss: 1.1173 - acc: 0.5145 - val_loss: 1.1594 - val_acc: 0.4811\n",
            "Epoch 67/1000\n",
            " - 0s - loss: 1.1326 - acc: 0.4983 - val_loss: 1.1638 - val_acc: 0.5070\n",
            "Epoch 68/1000\n",
            " - 0s - loss: 1.1194 - acc: 0.5204 - val_loss: 1.1402 - val_acc: 0.5178\n",
            "Epoch 69/1000\n",
            " - 0s - loss: 1.0971 - acc: 0.5244 - val_loss: 1.1354 - val_acc: 0.5113\n",
            "Epoch 70/1000\n",
            " - 0s - loss: 1.1110 - acc: 0.5096 - val_loss: 1.1260 - val_acc: 0.5291\n",
            "Epoch 71/1000\n",
            " - 0s - loss: 1.0916 - acc: 0.5292 - val_loss: 1.1512 - val_acc: 0.5070\n",
            "Epoch 72/1000\n",
            " - 0s - loss: 1.1039 - acc: 0.5193 - val_loss: 1.1275 - val_acc: 0.5200\n",
            "Epoch 73/1000\n",
            " - 0s - loss: 1.0853 - acc: 0.5287 - val_loss: 1.1218 - val_acc: 0.5232\n",
            "Epoch 74/1000\n",
            " - 0s - loss: 1.0957 - acc: 0.5227 - val_loss: 1.1172 - val_acc: 0.5286\n",
            "Epoch 75/1000\n",
            " - 0s - loss: 1.0804 - acc: 0.5307 - val_loss: 1.1384 - val_acc: 0.5194\n",
            "Epoch 76/1000\n",
            " - 0s - loss: 1.0860 - acc: 0.5274 - val_loss: 1.1212 - val_acc: 0.5200\n",
            "Epoch 77/1000\n",
            " - 0s - loss: 1.0758 - acc: 0.5341 - val_loss: 1.1169 - val_acc: 0.5216\n",
            "Epoch 78/1000\n",
            " - 0s - loss: 1.0804 - acc: 0.5323 - val_loss: 1.1152 - val_acc: 0.5264\n",
            "Epoch 79/1000\n",
            " - 0s - loss: 1.0708 - acc: 0.5373 - val_loss: 1.1319 - val_acc: 0.5097\n",
            "Epoch 80/1000\n",
            " - 0s - loss: 1.0743 - acc: 0.5371 - val_loss: 1.1118 - val_acc: 0.5264\n",
            "Epoch 81/1000\n",
            " - 0s - loss: 1.0659 - acc: 0.5355 - val_loss: 1.1061 - val_acc: 0.5264\n",
            "Epoch 82/1000\n",
            " - 0s - loss: 1.0663 - acc: 0.5377 - val_loss: 1.1128 - val_acc: 0.5264\n",
            "Epoch 83/1000\n",
            " - 0s - loss: 1.0642 - acc: 0.5402 - val_loss: 1.1122 - val_acc: 0.5248\n",
            "Epoch 84/1000\n",
            " - 0s - loss: 1.0582 - acc: 0.5461 - val_loss: 1.1027 - val_acc: 0.5286\n",
            "Epoch 85/1000\n",
            " - 0s - loss: 1.0548 - acc: 0.5413 - val_loss: 1.1036 - val_acc: 0.5345\n",
            "Epoch 86/1000\n",
            " - 0s - loss: 1.0513 - acc: 0.5432 - val_loss: 1.1084 - val_acc: 0.5227\n",
            "Epoch 87/1000\n",
            " - 0s - loss: 1.0528 - acc: 0.5416 - val_loss: 1.1061 - val_acc: 0.5302\n",
            "Epoch 88/1000\n",
            " - 0s - loss: 1.0491 - acc: 0.5402 - val_loss: 1.0997 - val_acc: 0.5307\n",
            "Epoch 89/1000\n",
            " - 0s - loss: 1.0394 - acc: 0.5540 - val_loss: 1.1017 - val_acc: 0.5313\n",
            "Epoch 90/1000\n",
            " - 0s - loss: 1.0396 - acc: 0.5476 - val_loss: 1.1059 - val_acc: 0.5356\n",
            "Epoch 91/1000\n",
            " - 0s - loss: 1.0408 - acc: 0.5492 - val_loss: 1.1006 - val_acc: 0.5351\n",
            "Epoch 92/1000\n",
            " - 0s - loss: 1.0322 - acc: 0.5510 - val_loss: 1.1035 - val_acc: 0.5318\n",
            "Epoch 93/1000\n",
            " - 0s - loss: 1.0357 - acc: 0.5497 - val_loss: 1.0977 - val_acc: 0.5329\n",
            "Epoch 94/1000\n",
            " - 0s - loss: 1.0331 - acc: 0.5535 - val_loss: 1.0934 - val_acc: 0.5399\n",
            "Epoch 95/1000\n",
            " - 0s - loss: 1.0209 - acc: 0.5578 - val_loss: 1.0981 - val_acc: 0.5405\n",
            "Epoch 96/1000\n",
            " - 0s - loss: 1.0211 - acc: 0.5573 - val_loss: 1.0964 - val_acc: 0.5356\n",
            "Epoch 97/1000\n",
            " - 0s - loss: 1.0203 - acc: 0.5564 - val_loss: 1.1015 - val_acc: 0.5356\n",
            "Epoch 98/1000\n",
            " - 0s - loss: 1.0202 - acc: 0.5513 - val_loss: 1.1056 - val_acc: 0.5248\n",
            "Epoch 99/1000\n",
            " - 0s - loss: 1.0273 - acc: 0.5510 - val_loss: 1.1169 - val_acc: 0.5367\n",
            "Epoch 100/1000\n",
            " - 0s - loss: 1.0291 - acc: 0.5521 - val_loss: 1.0976 - val_acc: 0.5345\n",
            "Epoch 101/1000\n",
            " - 0s - loss: 1.0131 - acc: 0.5594 - val_loss: 1.0925 - val_acc: 0.5345\n",
            "Epoch 102/1000\n",
            " - 0s - loss: 1.0249 - acc: 0.5535 - val_loss: 1.0938 - val_acc: 0.5394\n",
            "Epoch 103/1000\n",
            " - 0s - loss: 1.0138 - acc: 0.5546 - val_loss: 1.1103 - val_acc: 0.5302\n",
            "Epoch 104/1000\n",
            " - 0s - loss: 1.0134 - acc: 0.5566 - val_loss: 1.0984 - val_acc: 0.5383\n",
            "Epoch 105/1000\n",
            " - 0s - loss: 1.0088 - acc: 0.5605 - val_loss: 1.0997 - val_acc: 0.5383\n",
            "Epoch 106/1000\n",
            " - 0s - loss: 1.0137 - acc: 0.5621 - val_loss: 1.0992 - val_acc: 0.5421\n",
            "Epoch 107/1000\n",
            " - 0s - loss: 0.9986 - acc: 0.5648 - val_loss: 1.1048 - val_acc: 0.5356\n",
            "Epoch 108/1000\n",
            " - 0s - loss: 0.9995 - acc: 0.5634 - val_loss: 1.1011 - val_acc: 0.5405\n",
            "Epoch 109/1000\n",
            " - 0s - loss: 0.9971 - acc: 0.5657 - val_loss: 1.1009 - val_acc: 0.5405\n",
            "Epoch 110/1000\n",
            " - 0s - loss: 0.9913 - acc: 0.5767 - val_loss: 1.1061 - val_acc: 0.5280\n",
            "Epoch 111/1000\n",
            " - 0s - loss: 0.9890 - acc: 0.5754 - val_loss: 1.0899 - val_acc: 0.5426\n",
            "Epoch 112/1000\n",
            " - 0s - loss: 0.9850 - acc: 0.5787 - val_loss: 1.0983 - val_acc: 0.5399\n",
            "Epoch 113/1000\n",
            " - 0s - loss: 0.9793 - acc: 0.5776 - val_loss: 1.1022 - val_acc: 0.5388\n",
            "Epoch 114/1000\n",
            " - 0s - loss: 0.9745 - acc: 0.5848 - val_loss: 1.0922 - val_acc: 0.5453\n",
            "Epoch 115/1000\n",
            " - 0s - loss: 0.9697 - acc: 0.5808 - val_loss: 1.1024 - val_acc: 0.5421\n",
            "Epoch 116/1000\n",
            " - 0s - loss: 0.9744 - acc: 0.5749 - val_loss: 1.1008 - val_acc: 0.5297\n",
            "Epoch 117/1000\n",
            " - 0s - loss: 0.9689 - acc: 0.5832 - val_loss: 1.1123 - val_acc: 0.5351\n",
            "Epoch 118/1000\n",
            " - 0s - loss: 0.9733 - acc: 0.5810 - val_loss: 1.1180 - val_acc: 0.5151\n",
            "Epoch 119/1000\n",
            " - 0s - loss: 0.9838 - acc: 0.5621 - val_loss: 1.1177 - val_acc: 0.5351\n",
            "Epoch 120/1000\n",
            " - 0s - loss: 0.9763 - acc: 0.5729 - val_loss: 1.1061 - val_acc: 0.5372\n",
            "Epoch 121/1000\n",
            " - 0s - loss: 0.9661 - acc: 0.5864 - val_loss: 1.0987 - val_acc: 0.5394\n",
            "Epoch 122/1000\n",
            " - 0s - loss: 0.9623 - acc: 0.5868 - val_loss: 1.0995 - val_acc: 0.5415\n",
            "Epoch 123/1000\n",
            " - 0s - loss: 0.9560 - acc: 0.5893 - val_loss: 1.1119 - val_acc: 0.5399\n",
            "Epoch 124/1000\n",
            " - 0s - loss: 0.9640 - acc: 0.5896 - val_loss: 1.1082 - val_acc: 0.5361\n",
            "Epoch 125/1000\n",
            " - 0s - loss: 0.9539 - acc: 0.5902 - val_loss: 1.1082 - val_acc: 0.5378\n",
            "Epoch 126/1000\n",
            " - 0s - loss: 0.9597 - acc: 0.5853 - val_loss: 1.1027 - val_acc: 0.5356\n",
            "Epoch 127/1000\n",
            " - 0s - loss: 0.9464 - acc: 0.5927 - val_loss: 1.1166 - val_acc: 0.5259\n",
            "Epoch 128/1000\n",
            " - 0s - loss: 0.9374 - acc: 0.6004 - val_loss: 1.1212 - val_acc: 0.5405\n",
            "Epoch 129/1000\n",
            " - 0s - loss: 0.9468 - acc: 0.5977 - val_loss: 1.1092 - val_acc: 0.5356\n",
            "Epoch 130/1000\n",
            " - 0s - loss: 0.9342 - acc: 0.5911 - val_loss: 1.1180 - val_acc: 0.5421\n",
            "Epoch 131/1000\n",
            " - 0s - loss: 0.9450 - acc: 0.5927 - val_loss: 1.1287 - val_acc: 0.5156\n",
            "Epoch 132/1000\n",
            " - 0s - loss: 0.9459 - acc: 0.5875 - val_loss: 1.1076 - val_acc: 0.5415\n",
            "Epoch 133/1000\n",
            " - 0s - loss: 0.9296 - acc: 0.6019 - val_loss: 1.1052 - val_acc: 0.5383\n",
            "Epoch 134/1000\n",
            " - 0s - loss: 0.9232 - acc: 0.6096 - val_loss: 1.1017 - val_acc: 0.5491\n",
            "Epoch 135/1000\n",
            " - 0s - loss: 0.9224 - acc: 0.6105 - val_loss: 1.1084 - val_acc: 0.5512\n",
            "Epoch 136/1000\n",
            " - 0s - loss: 0.9222 - acc: 0.6074 - val_loss: 1.1237 - val_acc: 0.5345\n",
            "Epoch 137/1000\n",
            " - 0s - loss: 0.9203 - acc: 0.6148 - val_loss: 1.1068 - val_acc: 0.5469\n",
            "Epoch 138/1000\n",
            " - 0s - loss: 0.9062 - acc: 0.6116 - val_loss: 1.1164 - val_acc: 0.5464\n",
            "Epoch 139/1000\n",
            " - 0s - loss: 0.9031 - acc: 0.6168 - val_loss: 1.1387 - val_acc: 0.5237\n",
            "Epoch 140/1000\n",
            " - 0s - loss: 0.9089 - acc: 0.6107 - val_loss: 1.1449 - val_acc: 0.5324\n",
            "Epoch 141/1000\n",
            " - 0s - loss: 0.9263 - acc: 0.6112 - val_loss: 1.1463 - val_acc: 0.5135\n",
            "Epoch 142/1000\n",
            " - 0s - loss: 0.9161 - acc: 0.6028 - val_loss: 1.1372 - val_acc: 0.5345\n",
            "Epoch 143/1000\n",
            " - 0s - loss: 0.9165 - acc: 0.6085 - val_loss: 1.1458 - val_acc: 0.5340\n",
            "Epoch 144/1000\n",
            " - 0s - loss: 0.9225 - acc: 0.5985 - val_loss: 1.1450 - val_acc: 0.4881\n",
            "Epoch 145/1000\n",
            " - 0s - loss: 0.9338 - acc: 0.5929 - val_loss: 1.1038 - val_acc: 0.5518\n",
            "Epoch 146/1000\n",
            " - 0s - loss: 0.8973 - acc: 0.6233 - val_loss: 1.1311 - val_acc: 0.5394\n",
            "Epoch 147/1000\n",
            " - 0s - loss: 0.9061 - acc: 0.6139 - val_loss: 1.1267 - val_acc: 0.5264\n",
            "Epoch 148/1000\n",
            " - 0s - loss: 0.8917 - acc: 0.6206 - val_loss: 1.1310 - val_acc: 0.5291\n",
            "Epoch 149/1000\n",
            " - 0s - loss: 0.8984 - acc: 0.6157 - val_loss: 1.1181 - val_acc: 0.5502\n",
            "Epoch 150/1000\n",
            " - 0s - loss: 0.8826 - acc: 0.6326 - val_loss: 1.1284 - val_acc: 0.5480\n",
            "Epoch 151/1000\n",
            " - 0s - loss: 0.8770 - acc: 0.6342 - val_loss: 1.1401 - val_acc: 0.5264\n",
            "Epoch 152/1000\n",
            " - 0s - loss: 0.8792 - acc: 0.6355 - val_loss: 1.1252 - val_acc: 0.5415\n",
            "Epoch 153/1000\n",
            " - 0s - loss: 0.8664 - acc: 0.6339 - val_loss: 1.1433 - val_acc: 0.5307\n",
            "Epoch 154/1000\n",
            " - 0s - loss: 0.8618 - acc: 0.6400 - val_loss: 1.1500 - val_acc: 0.5216\n",
            "Epoch 155/1000\n",
            " - 0s - loss: 0.8612 - acc: 0.6389 - val_loss: 1.1452 - val_acc: 0.5485\n",
            "Epoch 156/1000\n",
            " - 0s - loss: 0.8570 - acc: 0.6445 - val_loss: 1.1562 - val_acc: 0.5329\n",
            "Epoch 157/1000\n",
            " - 0s - loss: 0.8639 - acc: 0.6364 - val_loss: 1.1422 - val_acc: 0.5340\n",
            "Epoch 158/1000\n",
            " - 0s - loss: 0.8432 - acc: 0.6526 - val_loss: 1.1445 - val_acc: 0.5345\n",
            "Epoch 159/1000\n",
            " - 0s - loss: 0.8565 - acc: 0.6456 - val_loss: 1.1474 - val_acc: 0.5361\n",
            "Epoch 160/1000\n",
            " - 0s - loss: 0.8429 - acc: 0.6452 - val_loss: 1.1587 - val_acc: 0.5345\n",
            "Epoch 161/1000\n",
            " - 0s - loss: 0.8374 - acc: 0.6481 - val_loss: 1.1573 - val_acc: 0.5334\n",
            "Epoch 162/1000\n",
            " - 0s - loss: 0.8558 - acc: 0.6438 - val_loss: 1.2032 - val_acc: 0.5254\n",
            "Epoch 163/1000\n",
            " - 0s - loss: 0.8798 - acc: 0.6297 - val_loss: 1.1883 - val_acc: 0.5032\n",
            "Epoch 164/1000\n",
            " - 0s - loss: 0.8770 - acc: 0.6213 - val_loss: 1.1770 - val_acc: 0.5378\n",
            "Epoch 165/1000\n",
            " - 0s - loss: 0.8743 - acc: 0.6299 - val_loss: 1.1630 - val_acc: 0.5237\n",
            "Epoch 166/1000\n",
            " - 0s - loss: 0.8568 - acc: 0.6373 - val_loss: 1.1831 - val_acc: 0.5092\n",
            "Epoch 167/1000\n",
            " - 0s - loss: 0.8696 - acc: 0.6391 - val_loss: 1.1505 - val_acc: 0.5318\n",
            "Epoch 168/1000\n",
            " - 0s - loss: 0.8559 - acc: 0.6456 - val_loss: 1.1361 - val_acc: 0.5405\n",
            "Epoch 169/1000\n",
            " - 0s - loss: 0.8371 - acc: 0.6549 - val_loss: 1.1437 - val_acc: 0.5367\n",
            "Epoch 170/1000\n",
            " - 0s - loss: 0.8492 - acc: 0.6423 - val_loss: 1.1484 - val_acc: 0.5469\n",
            "Epoch 171/1000\n",
            " - 0s - loss: 0.8281 - acc: 0.6538 - val_loss: 1.1774 - val_acc: 0.5280\n",
            "Epoch 172/1000\n",
            " - 0s - loss: 0.8243 - acc: 0.6587 - val_loss: 1.1749 - val_acc: 0.5270\n",
            "Epoch 173/1000\n",
            " - 0s - loss: 0.8164 - acc: 0.6662 - val_loss: 1.1776 - val_acc: 0.5421\n",
            "Epoch 174/1000\n",
            " - 0s - loss: 0.8154 - acc: 0.6600 - val_loss: 1.1734 - val_acc: 0.5318\n",
            "Epoch 175/1000\n",
            " - 0s - loss: 0.7961 - acc: 0.6695 - val_loss: 1.1736 - val_acc: 0.5334\n",
            "Epoch 176/1000\n",
            " - 0s - loss: 0.7873 - acc: 0.6792 - val_loss: 1.1955 - val_acc: 0.5221\n",
            "Epoch 177/1000\n",
            " - 0s - loss: 0.8107 - acc: 0.6594 - val_loss: 1.1746 - val_acc: 0.5367\n",
            "Epoch 178/1000\n",
            " - 0s - loss: 0.8011 - acc: 0.6679 - val_loss: 1.1748 - val_acc: 0.5480\n",
            "Epoch 179/1000\n",
            " - 0s - loss: 0.7833 - acc: 0.6781 - val_loss: 1.1811 - val_acc: 0.5280\n",
            "Epoch 180/1000\n",
            " - 0s - loss: 0.7741 - acc: 0.6810 - val_loss: 1.1813 - val_acc: 0.5415\n",
            "Epoch 181/1000\n",
            " - 0s - loss: 0.7963 - acc: 0.6691 - val_loss: 1.2019 - val_acc: 0.5259\n",
            "Epoch 182/1000\n",
            " - 0s - loss: 0.7919 - acc: 0.6616 - val_loss: 1.2029 - val_acc: 0.5329\n",
            "Epoch 183/1000\n",
            " - 0s - loss: 0.7885 - acc: 0.6765 - val_loss: 1.2039 - val_acc: 0.5361\n",
            "Epoch 184/1000\n",
            " - 0s - loss: 0.7771 - acc: 0.6778 - val_loss: 1.1733 - val_acc: 0.5340\n",
            "Epoch 185/1000\n",
            " - 0s - loss: 0.7652 - acc: 0.6934 - val_loss: 1.1822 - val_acc: 0.5431\n",
            "Epoch 186/1000\n",
            " - 0s - loss: 0.7533 - acc: 0.6938 - val_loss: 1.2046 - val_acc: 0.5329\n",
            "Epoch 187/1000\n",
            " - 0s - loss: 0.7624 - acc: 0.6830 - val_loss: 1.1851 - val_acc: 0.5491\n",
            "Epoch 188/1000\n",
            " - 0s - loss: 0.7554 - acc: 0.6907 - val_loss: 1.2210 - val_acc: 0.5286\n",
            "Epoch 189/1000\n",
            " - 0s - loss: 0.7631 - acc: 0.6925 - val_loss: 1.2205 - val_acc: 0.5264\n",
            "Epoch 190/1000\n",
            " - 0s - loss: 0.7457 - acc: 0.6948 - val_loss: 1.2212 - val_acc: 0.5475\n",
            "Epoch 191/1000\n",
            " - 0s - loss: 0.7512 - acc: 0.6900 - val_loss: 1.2390 - val_acc: 0.5043\n",
            "Epoch 192/1000\n",
            " - 0s - loss: 0.7562 - acc: 0.6932 - val_loss: 1.2481 - val_acc: 0.5291\n",
            "Epoch 193/1000\n",
            " - 0s - loss: 0.7655 - acc: 0.6808 - val_loss: 1.2481 - val_acc: 0.5022\n",
            "Epoch 194/1000\n",
            " - 0s - loss: 0.7729 - acc: 0.6796 - val_loss: 1.2568 - val_acc: 0.5237\n",
            "Epoch 195/1000\n",
            " - 0s - loss: 0.7829 - acc: 0.6740 - val_loss: 1.2007 - val_acc: 0.5399\n",
            "Epoch 196/1000\n",
            " - 0s - loss: 0.7333 - acc: 0.7051 - val_loss: 1.2094 - val_acc: 0.5318\n",
            "Epoch 197/1000\n",
            " - 0s - loss: 0.7413 - acc: 0.6916 - val_loss: 1.2195 - val_acc: 0.5405\n",
            "Epoch 198/1000\n",
            " - 0s - loss: 0.7400 - acc: 0.7004 - val_loss: 1.2080 - val_acc: 0.5340\n",
            "Epoch 199/1000\n",
            " - 0s - loss: 0.7291 - acc: 0.7058 - val_loss: 1.2438 - val_acc: 0.5356\n",
            "Epoch 200/1000\n",
            " - 0s - loss: 0.7341 - acc: 0.7040 - val_loss: 1.2504 - val_acc: 0.5394\n",
            "Epoch 201/1000\n",
            " - 0s - loss: 0.7208 - acc: 0.7078 - val_loss: 1.2454 - val_acc: 0.5200\n",
            "Epoch 202/1000\n",
            " - 0s - loss: 0.7168 - acc: 0.7085 - val_loss: 1.2255 - val_acc: 0.5340\n",
            "Epoch 203/1000\n",
            " - 0s - loss: 0.7126 - acc: 0.7134 - val_loss: 1.2550 - val_acc: 0.5458\n",
            "Epoch 204/1000\n",
            " - 0s - loss: 0.7172 - acc: 0.7080 - val_loss: 1.2649 - val_acc: 0.5119\n",
            "Epoch 205/1000\n",
            " - 0s - loss: 0.7171 - acc: 0.7114 - val_loss: 1.2494 - val_acc: 0.5372\n",
            "Epoch 206/1000\n",
            " - 0s - loss: 0.7057 - acc: 0.7141 - val_loss: 1.2408 - val_acc: 0.5286\n",
            "Epoch 207/1000\n",
            " - 0s - loss: 0.6952 - acc: 0.7188 - val_loss: 1.2567 - val_acc: 0.5367\n",
            "Epoch 208/1000\n",
            " - 0s - loss: 0.6982 - acc: 0.7180 - val_loss: 1.2586 - val_acc: 0.5378\n",
            "Epoch 209/1000\n",
            " - 0s - loss: 0.7037 - acc: 0.7191 - val_loss: 1.2544 - val_acc: 0.5173\n",
            "Epoch 210/1000\n",
            " - 0s - loss: 0.6776 - acc: 0.7252 - val_loss: 1.2425 - val_acc: 0.5539\n",
            "Epoch 211/1000\n",
            " - 0s - loss: 0.6836 - acc: 0.7207 - val_loss: 1.2608 - val_acc: 0.5286\n",
            "Epoch 212/1000\n",
            " - 0s - loss: 0.6794 - acc: 0.7233 - val_loss: 1.2759 - val_acc: 0.5361\n",
            "Epoch 213/1000\n",
            " - 0s - loss: 0.6789 - acc: 0.7211 - val_loss: 1.2516 - val_acc: 0.5329\n",
            "Epoch 214/1000\n",
            " - 0s - loss: 0.6656 - acc: 0.7348 - val_loss: 1.2937 - val_acc: 0.5378\n",
            "Epoch 215/1000\n",
            " - 0s - loss: 0.6741 - acc: 0.7301 - val_loss: 1.3083 - val_acc: 0.5151\n",
            "Epoch 216/1000\n",
            " - 0s - loss: 0.6881 - acc: 0.7143 - val_loss: 1.3634 - val_acc: 0.5194\n",
            "Epoch 217/1000\n",
            " - 0s - loss: 0.7171 - acc: 0.6950 - val_loss: 1.3102 - val_acc: 0.4978\n",
            "Epoch 218/1000\n",
            " - 0s - loss: 0.7076 - acc: 0.7065 - val_loss: 1.2787 - val_acc: 0.5410\n",
            "Epoch 219/1000\n",
            " - 0s - loss: 0.6830 - acc: 0.7270 - val_loss: 1.3248 - val_acc: 0.5216\n",
            "Epoch 220/1000\n",
            " - 0s - loss: 0.7045 - acc: 0.7085 - val_loss: 1.2529 - val_acc: 0.5200\n",
            "Epoch 221/1000\n",
            " - 0s - loss: 0.6748 - acc: 0.7191 - val_loss: 1.2639 - val_acc: 0.5372\n",
            "Epoch 222/1000\n",
            " - 0s - loss: 0.6976 - acc: 0.7101 - val_loss: 1.2954 - val_acc: 0.5221\n",
            "Epoch 223/1000\n",
            " - 0s - loss: 0.6919 - acc: 0.7231 - val_loss: 1.3056 - val_acc: 0.5086\n",
            "Epoch 224/1000\n",
            " - 0s - loss: 0.6763 - acc: 0.7188 - val_loss: 1.2807 - val_acc: 0.5464\n",
            "Epoch 225/1000\n",
            " - 0s - loss: 0.6887 - acc: 0.7220 - val_loss: 1.2802 - val_acc: 0.5183\n",
            "Epoch 226/1000\n",
            " - 0s - loss: 0.6754 - acc: 0.7313 - val_loss: 1.2835 - val_acc: 0.5237\n",
            "Epoch 227/1000\n",
            " - 0s - loss: 0.6534 - acc: 0.7375 - val_loss: 1.2970 - val_acc: 0.5534\n",
            "Epoch 228/1000\n",
            " - 0s - loss: 0.6548 - acc: 0.7391 - val_loss: 1.2790 - val_acc: 0.5448\n",
            "Epoch 229/1000\n",
            " - 0s - loss: 0.6357 - acc: 0.7457 - val_loss: 1.2990 - val_acc: 0.5178\n",
            "Epoch 230/1000\n",
            " - 0s - loss: 0.6546 - acc: 0.7396 - val_loss: 1.3111 - val_acc: 0.5388\n",
            "Epoch 231/1000\n",
            " - 0s - loss: 0.6321 - acc: 0.7536 - val_loss: 1.3400 - val_acc: 0.5372\n",
            "Epoch 232/1000\n",
            " - 0s - loss: 0.6306 - acc: 0.7448 - val_loss: 1.3294 - val_acc: 0.5243\n",
            "Epoch 233/1000\n",
            " - 0s - loss: 0.6304 - acc: 0.7531 - val_loss: 1.3270 - val_acc: 0.5361\n",
            "Epoch 234/1000\n",
            " - 0s - loss: 0.6108 - acc: 0.7553 - val_loss: 1.3535 - val_acc: 0.5221\n",
            "Epoch 235/1000\n",
            " - 0s - loss: 0.6312 - acc: 0.7479 - val_loss: 1.3538 - val_acc: 0.5340\n",
            "Epoch 236/1000\n",
            " - 0s - loss: 0.6281 - acc: 0.7470 - val_loss: 1.3367 - val_acc: 0.5140\n",
            "Epoch 237/1000\n",
            " - 0s - loss: 0.6109 - acc: 0.7650 - val_loss: 1.3269 - val_acc: 0.5383\n",
            "Epoch 238/1000\n",
            " - 0s - loss: 0.6145 - acc: 0.7585 - val_loss: 1.3443 - val_acc: 0.5340\n",
            "Epoch 239/1000\n",
            " - 0s - loss: 0.6097 - acc: 0.7549 - val_loss: 1.3233 - val_acc: 0.5227\n",
            "Epoch 240/1000\n",
            " - 0s - loss: 0.5886 - acc: 0.7713 - val_loss: 1.3157 - val_acc: 0.5410\n",
            "Epoch 241/1000\n",
            " - 0s - loss: 0.5931 - acc: 0.7731 - val_loss: 1.3530 - val_acc: 0.5475\n",
            "Epoch 242/1000\n",
            " - 0s - loss: 0.5983 - acc: 0.7617 - val_loss: 1.3679 - val_acc: 0.5151\n",
            "Epoch 243/1000\n",
            " - 0s - loss: 0.5937 - acc: 0.7709 - val_loss: 1.3850 - val_acc: 0.5378\n",
            "Epoch 244/1000\n",
            " - 0s - loss: 0.6034 - acc: 0.7617 - val_loss: 1.3676 - val_acc: 0.5237\n",
            "Epoch 245/1000\n",
            " - 0s - loss: 0.6026 - acc: 0.7623 - val_loss: 1.3610 - val_acc: 0.5426\n",
            "Epoch 246/1000\n",
            " - 0s - loss: 0.5747 - acc: 0.7749 - val_loss: 1.3496 - val_acc: 0.5388\n",
            "Epoch 247/1000\n",
            " - 0s - loss: 0.5778 - acc: 0.7720 - val_loss: 1.3634 - val_acc: 0.5205\n",
            "Epoch 248/1000\n",
            " - 0s - loss: 0.5676 - acc: 0.7768 - val_loss: 1.3843 - val_acc: 0.5415\n",
            "Epoch 249/1000\n",
            " - 0s - loss: 0.5702 - acc: 0.7740 - val_loss: 1.3737 - val_acc: 0.5318\n",
            "Epoch 250/1000\n",
            " - 0s - loss: 0.5587 - acc: 0.7930 - val_loss: 1.3945 - val_acc: 0.5367\n",
            "Epoch 251/1000\n",
            " - 0s - loss: 0.5611 - acc: 0.7803 - val_loss: 1.3938 - val_acc: 0.5518\n",
            "Epoch 252/1000\n",
            " - 0s - loss: 0.5639 - acc: 0.7720 - val_loss: 1.4185 - val_acc: 0.5227\n",
            "Epoch 253/1000\n",
            " - 0s - loss: 0.5568 - acc: 0.7797 - val_loss: 1.3878 - val_acc: 0.5270\n",
            "Epoch 254/1000\n",
            " - 0s - loss: 0.5496 - acc: 0.7860 - val_loss: 1.4320 - val_acc: 0.5297\n",
            "Epoch 255/1000\n",
            " - 0s - loss: 0.5576 - acc: 0.7831 - val_loss: 1.3994 - val_acc: 0.5361\n",
            "Epoch 256/1000\n",
            " - 0s - loss: 0.5444 - acc: 0.7912 - val_loss: 1.4064 - val_acc: 0.5367\n",
            "Epoch 257/1000\n",
            " - 0s - loss: 0.5284 - acc: 0.7909 - val_loss: 1.4155 - val_acc: 0.5270\n",
            "Epoch 258/1000\n",
            " - 0s - loss: 0.5342 - acc: 0.7948 - val_loss: 1.4258 - val_acc: 0.5280\n",
            "Epoch 259/1000\n",
            " - 0s - loss: 0.5396 - acc: 0.7907 - val_loss: 1.4522 - val_acc: 0.5194\n",
            "Epoch 260/1000\n",
            " - 0s - loss: 0.5340 - acc: 0.7892 - val_loss: 1.4812 - val_acc: 0.5291\n",
            "Epoch 261/1000\n",
            " - 0s - loss: 0.5565 - acc: 0.7792 - val_loss: 1.4739 - val_acc: 0.5000\n",
            "Epoch 262/1000\n",
            " - 0s - loss: 0.5756 - acc: 0.7727 - val_loss: 1.5069 - val_acc: 0.5356\n",
            "Epoch 263/1000\n",
            " - 0s - loss: 0.5652 - acc: 0.7653 - val_loss: 1.4339 - val_acc: 0.5237\n",
            "Epoch 264/1000\n",
            " - 0s - loss: 0.5399 - acc: 0.7849 - val_loss: 1.4487 - val_acc: 0.5092\n",
            "Epoch 265/1000\n",
            " - 0s - loss: 0.5484 - acc: 0.7839 - val_loss: 1.4431 - val_acc: 0.5485\n",
            "Epoch 266/1000\n",
            " - 0s - loss: 0.5387 - acc: 0.7878 - val_loss: 1.4367 - val_acc: 0.5378\n",
            "Epoch 267/1000\n",
            " - 0s - loss: 0.5130 - acc: 0.8000 - val_loss: 1.4563 - val_acc: 0.5070\n",
            "Epoch 268/1000\n",
            " - 0s - loss: 0.5231 - acc: 0.7941 - val_loss: 1.4681 - val_acc: 0.5453\n",
            "Epoch 269/1000\n",
            " - 0s - loss: 0.5182 - acc: 0.8008 - val_loss: 1.4857 - val_acc: 0.5313\n",
            "Epoch 270/1000\n",
            " - 0s - loss: 0.5198 - acc: 0.7923 - val_loss: 1.4534 - val_acc: 0.5221\n",
            "Epoch 271/1000\n",
            " - 0s - loss: 0.5123 - acc: 0.8035 - val_loss: 1.5008 - val_acc: 0.5491\n",
            "Epoch 272/1000\n",
            " - 0s - loss: 0.5103 - acc: 0.8008 - val_loss: 1.5265 - val_acc: 0.5108\n",
            "Epoch 273/1000\n",
            " - 0s - loss: 0.5038 - acc: 0.8022 - val_loss: 1.4660 - val_acc: 0.5378\n",
            "Epoch 274/1000\n",
            " - 0s - loss: 0.4981 - acc: 0.8141 - val_loss: 1.4946 - val_acc: 0.5399\n",
            "Epoch 275/1000\n",
            " - 0s - loss: 0.5072 - acc: 0.7991 - val_loss: 1.5288 - val_acc: 0.5140\n",
            "Epoch 276/1000\n",
            " - 0s - loss: 0.4968 - acc: 0.8051 - val_loss: 1.4831 - val_acc: 0.5280\n",
            "Epoch 277/1000\n",
            " - 0s - loss: 0.4797 - acc: 0.8191 - val_loss: 1.4915 - val_acc: 0.5399\n",
            "Epoch 278/1000\n",
            " - 0s - loss: 0.4966 - acc: 0.8056 - val_loss: 1.5255 - val_acc: 0.5259\n",
            "Epoch 279/1000\n",
            " - 0s - loss: 0.4855 - acc: 0.8040 - val_loss: 1.4888 - val_acc: 0.5173\n",
            "Epoch 280/1000\n",
            " - 0s - loss: 0.4829 - acc: 0.8139 - val_loss: 1.4894 - val_acc: 0.5453\n",
            "Epoch 281/1000\n",
            " - 0s - loss: 0.4784 - acc: 0.8213 - val_loss: 1.5356 - val_acc: 0.5334\n",
            "Epoch 282/1000\n",
            " - 0s - loss: 0.4674 - acc: 0.8178 - val_loss: 1.5436 - val_acc: 0.5275\n",
            "Epoch 283/1000\n",
            " - 0s - loss: 0.4813 - acc: 0.8166 - val_loss: 1.5280 - val_acc: 0.5286\n",
            "Epoch 284/1000\n",
            " - 0s - loss: 0.4715 - acc: 0.8222 - val_loss: 1.5318 - val_acc: 0.5469\n",
            "Epoch 285/1000\n",
            " - 0s - loss: 0.4679 - acc: 0.8204 - val_loss: 1.5260 - val_acc: 0.5232\n",
            "Epoch 286/1000\n",
            " - 0s - loss: 0.4645 - acc: 0.8232 - val_loss: 1.5375 - val_acc: 0.5421\n",
            "Epoch 287/1000\n",
            " - 0s - loss: 0.4593 - acc: 0.8249 - val_loss: 1.5420 - val_acc: 0.5264\n",
            "Epoch 288/1000\n",
            " - 0s - loss: 0.4559 - acc: 0.8277 - val_loss: 1.5683 - val_acc: 0.5367\n",
            "Epoch 289/1000\n",
            " - 0s - loss: 0.4754 - acc: 0.8123 - val_loss: 1.5594 - val_acc: 0.5340\n",
            "Epoch 290/1000\n",
            " - 0s - loss: 0.4585 - acc: 0.8245 - val_loss: 1.5711 - val_acc: 0.5318\n",
            "Epoch 291/1000\n",
            " - 0s - loss: 0.4562 - acc: 0.8238 - val_loss: 1.5502 - val_acc: 0.5302\n",
            "Epoch 292/1000\n",
            " - 0s - loss: 0.4486 - acc: 0.8299 - val_loss: 1.5804 - val_acc: 0.5383\n",
            "Epoch 293/1000\n",
            " - 0s - loss: 0.4495 - acc: 0.8265 - val_loss: 1.5746 - val_acc: 0.5313\n",
            "Epoch 294/1000\n",
            " - 0s - loss: 0.4378 - acc: 0.8335 - val_loss: 1.5529 - val_acc: 0.5291\n",
            "Epoch 295/1000\n",
            " - 0s - loss: 0.4494 - acc: 0.8308 - val_loss: 1.6257 - val_acc: 0.5340\n",
            "Epoch 296/1000\n",
            " - 0s - loss: 0.4416 - acc: 0.8295 - val_loss: 1.6187 - val_acc: 0.5178\n",
            "Epoch 297/1000\n",
            " - 0s - loss: 0.4398 - acc: 0.8326 - val_loss: 1.6360 - val_acc: 0.5361\n",
            "Epoch 298/1000\n",
            " - 0s - loss: 0.4454 - acc: 0.8272 - val_loss: 1.6527 - val_acc: 0.5070\n",
            "Epoch 299/1000\n",
            " - 0s - loss: 0.4698 - acc: 0.8121 - val_loss: 1.7082 - val_acc: 0.5372\n",
            "Epoch 300/1000\n",
            " - 0s - loss: 0.4839 - acc: 0.8018 - val_loss: 1.6097 - val_acc: 0.4941\n",
            "Epoch 301/1000\n",
            " - 0s - loss: 0.4829 - acc: 0.8081 - val_loss: 1.5983 - val_acc: 0.5307\n",
            "Epoch 302/1000\n",
            " - 0s - loss: 0.4686 - acc: 0.8169 - val_loss: 1.5849 - val_acc: 0.5286\n",
            "Epoch 303/1000\n",
            " - 0s - loss: 0.4500 - acc: 0.8311 - val_loss: 1.5835 - val_acc: 0.5092\n",
            "Epoch 304/1000\n",
            " - 0s - loss: 0.4576 - acc: 0.8297 - val_loss: 1.6203 - val_acc: 0.5334\n",
            "Epoch 305/1000\n",
            " - 0s - loss: 0.4766 - acc: 0.8115 - val_loss: 1.6017 - val_acc: 0.5351\n",
            "Epoch 306/1000\n",
            " - 0s - loss: 0.4325 - acc: 0.8329 - val_loss: 1.6250 - val_acc: 0.5259\n",
            "Epoch 307/1000\n",
            " - 0s - loss: 0.4667 - acc: 0.8207 - val_loss: 1.6411 - val_acc: 0.5291\n",
            "Epoch 308/1000\n",
            " - 0s - loss: 0.4580 - acc: 0.8191 - val_loss: 1.5854 - val_acc: 0.5135\n",
            "Epoch 309/1000\n",
            " - 0s - loss: 0.4497 - acc: 0.8250 - val_loss: 1.6030 - val_acc: 0.5324\n",
            "Epoch 310/1000\n",
            " - 0s - loss: 0.4373 - acc: 0.8347 - val_loss: 1.6457 - val_acc: 0.5361\n",
            "Epoch 311/1000\n",
            " - 0s - loss: 0.4140 - acc: 0.8409 - val_loss: 1.6387 - val_acc: 0.5221\n",
            "Epoch 312/1000\n",
            " - 0s - loss: 0.4253 - acc: 0.8376 - val_loss: 1.6255 - val_acc: 0.5415\n",
            "Epoch 313/1000\n",
            " - 0s - loss: 0.4006 - acc: 0.8511 - val_loss: 1.6792 - val_acc: 0.5394\n",
            "Epoch 314/1000\n",
            " - 0s - loss: 0.4340 - acc: 0.8286 - val_loss: 1.6226 - val_acc: 0.5394\n",
            "Epoch 315/1000\n",
            " - 0s - loss: 0.4056 - acc: 0.8502 - val_loss: 1.6351 - val_acc: 0.5237\n",
            "Epoch 316/1000\n",
            " - 0s - loss: 0.4058 - acc: 0.8497 - val_loss: 1.6617 - val_acc: 0.5200\n",
            "Epoch 317/1000\n",
            " - 0s - loss: 0.3880 - acc: 0.8552 - val_loss: 1.6565 - val_acc: 0.5491\n",
            "Epoch 318/1000\n",
            " - 0s - loss: 0.4072 - acc: 0.8461 - val_loss: 1.6784 - val_acc: 0.5227\n",
            "Epoch 319/1000\n",
            " - 0s - loss: 0.3994 - acc: 0.8498 - val_loss: 1.6863 - val_acc: 0.5248\n",
            "Epoch 320/1000\n",
            " - 0s - loss: 0.3954 - acc: 0.8531 - val_loss: 1.7099 - val_acc: 0.5421\n",
            "Epoch 321/1000\n",
            " - 0s - loss: 0.3983 - acc: 0.8502 - val_loss: 1.7125 - val_acc: 0.5302\n",
            "Epoch 322/1000\n",
            " - 0s - loss: 0.3822 - acc: 0.8556 - val_loss: 1.7240 - val_acc: 0.5334\n",
            "Epoch 323/1000\n",
            " - 0s - loss: 0.3812 - acc: 0.8572 - val_loss: 1.7022 - val_acc: 0.5340\n",
            "Epoch 324/1000\n",
            " - 0s - loss: 0.3689 - acc: 0.8612 - val_loss: 1.7046 - val_acc: 0.5372\n",
            "Epoch 325/1000\n",
            " - 0s - loss: 0.3891 - acc: 0.8516 - val_loss: 1.7142 - val_acc: 0.5448\n",
            "Epoch 326/1000\n",
            " - 0s - loss: 0.3794 - acc: 0.8585 - val_loss: 1.7122 - val_acc: 0.5232\n",
            "Epoch 327/1000\n",
            " - 0s - loss: 0.3683 - acc: 0.8680 - val_loss: 1.7050 - val_acc: 0.5340\n",
            "Epoch 328/1000\n",
            " - 0s - loss: 0.3671 - acc: 0.8606 - val_loss: 1.7698 - val_acc: 0.5410\n",
            "Epoch 329/1000\n",
            " - 0s - loss: 0.3881 - acc: 0.8527 - val_loss: 1.7487 - val_acc: 0.5280\n",
            "Epoch 330/1000\n",
            " - 0s - loss: 0.3644 - acc: 0.8597 - val_loss: 1.7585 - val_acc: 0.5248\n",
            "Epoch 331/1000\n",
            " - 0s - loss: 0.3828 - acc: 0.8542 - val_loss: 1.7752 - val_acc: 0.5361\n",
            "Epoch 332/1000\n",
            " - 0s - loss: 0.3803 - acc: 0.8554 - val_loss: 1.7796 - val_acc: 0.5232\n",
            "Epoch 333/1000\n",
            " - 0s - loss: 0.3840 - acc: 0.8565 - val_loss: 1.7294 - val_acc: 0.5216\n",
            "Epoch 334/1000\n",
            " - 0s - loss: 0.3924 - acc: 0.8475 - val_loss: 1.7566 - val_acc: 0.5270\n",
            "Epoch 335/1000\n",
            " - 0s - loss: 0.3788 - acc: 0.8574 - val_loss: 1.7165 - val_acc: 0.5361\n",
            "Epoch 336/1000\n",
            " - 0s - loss: 0.3554 - acc: 0.8689 - val_loss: 1.7245 - val_acc: 0.5318\n",
            "Epoch 337/1000\n",
            " - 0s - loss: 0.3685 - acc: 0.8581 - val_loss: 1.7869 - val_acc: 0.5329\n",
            "Epoch 338/1000\n",
            " - 0s - loss: 0.3574 - acc: 0.8637 - val_loss: 1.7690 - val_acc: 0.5356\n",
            "Epoch 339/1000\n",
            " - 0s - loss: 0.3445 - acc: 0.8707 - val_loss: 1.7784 - val_acc: 0.5324\n",
            "Epoch 340/1000\n",
            " - 0s - loss: 0.3621 - acc: 0.8642 - val_loss: 1.8606 - val_acc: 0.5183\n",
            "Epoch 341/1000\n",
            " - 0s - loss: 0.3716 - acc: 0.8565 - val_loss: 1.8402 - val_acc: 0.5227\n",
            "Epoch 342/1000\n",
            " - 0s - loss: 0.3697 - acc: 0.8578 - val_loss: 1.8685 - val_acc: 0.5248\n",
            "Epoch 343/1000\n",
            " - 0s - loss: 0.3725 - acc: 0.8563 - val_loss: 1.8286 - val_acc: 0.5200\n",
            "Epoch 344/1000\n",
            " - 0s - loss: 0.3606 - acc: 0.8646 - val_loss: 1.8204 - val_acc: 0.5426\n",
            "Epoch 345/1000\n",
            " - 0s - loss: 0.3662 - acc: 0.8651 - val_loss: 1.7888 - val_acc: 0.5270\n",
            "Epoch 346/1000\n",
            " - 0s - loss: 0.3473 - acc: 0.8734 - val_loss: 1.8079 - val_acc: 0.5264\n",
            "Epoch 347/1000\n",
            " - 0s - loss: 0.3461 - acc: 0.8723 - val_loss: 1.8147 - val_acc: 0.5496\n",
            "Epoch 348/1000\n",
            " - 0s - loss: 0.3454 - acc: 0.8653 - val_loss: 1.8044 - val_acc: 0.5194\n",
            "Epoch 349/1000\n",
            " - 0s - loss: 0.3345 - acc: 0.8748 - val_loss: 1.8402 - val_acc: 0.5329\n",
            "Epoch 350/1000\n",
            " - 0s - loss: 0.3304 - acc: 0.8781 - val_loss: 1.8594 - val_acc: 0.5491\n",
            "Epoch 351/1000\n",
            " - 0s - loss: 0.3305 - acc: 0.8734 - val_loss: 1.8460 - val_acc: 0.5232\n",
            "Epoch 352/1000\n",
            " - 0s - loss: 0.3411 - acc: 0.8684 - val_loss: 1.8777 - val_acc: 0.5324\n",
            "Epoch 353/1000\n",
            " - 0s - loss: 0.3290 - acc: 0.8772 - val_loss: 1.9009 - val_acc: 0.5405\n",
            "Epoch 354/1000\n",
            " - 0s - loss: 0.3290 - acc: 0.8718 - val_loss: 1.8682 - val_acc: 0.5329\n",
            "Epoch 355/1000\n",
            " - 0s - loss: 0.3242 - acc: 0.8772 - val_loss: 1.8664 - val_acc: 0.5275\n",
            "Epoch 356/1000\n",
            " - 0s - loss: 0.3289 - acc: 0.8788 - val_loss: 1.9080 - val_acc: 0.5334\n",
            "Epoch 357/1000\n",
            " - 0s - loss: 0.3292 - acc: 0.8756 - val_loss: 1.8753 - val_acc: 0.5372\n",
            "Epoch 358/1000\n",
            " - 0s - loss: 0.3260 - acc: 0.8772 - val_loss: 1.8619 - val_acc: 0.5194\n",
            "Epoch 359/1000\n",
            " - 0s - loss: 0.3249 - acc: 0.8745 - val_loss: 1.9456 - val_acc: 0.5340\n",
            "Epoch 360/1000\n",
            " - 0s - loss: 0.3302 - acc: 0.8775 - val_loss: 1.8711 - val_acc: 0.5329\n",
            "Epoch 361/1000\n",
            " - 0s - loss: 0.3155 - acc: 0.8838 - val_loss: 1.8643 - val_acc: 0.5453\n",
            "Epoch 362/1000\n",
            " - 0s - loss: 0.3109 - acc: 0.8878 - val_loss: 1.9371 - val_acc: 0.5254\n",
            "Epoch 363/1000\n",
            " - 0s - loss: 0.3294 - acc: 0.8739 - val_loss: 1.9120 - val_acc: 0.5361\n",
            "Epoch 364/1000\n",
            " - 0s - loss: 0.2938 - acc: 0.8908 - val_loss: 1.8881 - val_acc: 0.5415\n",
            "Epoch 365/1000\n",
            " - 0s - loss: 0.3052 - acc: 0.8873 - val_loss: 1.9252 - val_acc: 0.5415\n",
            "Epoch 366/1000\n",
            " - 0s - loss: 0.3210 - acc: 0.8799 - val_loss: 1.9080 - val_acc: 0.5334\n",
            "Epoch 367/1000\n",
            " - 0s - loss: 0.3003 - acc: 0.8880 - val_loss: 1.9556 - val_acc: 0.5162\n",
            "Epoch 368/1000\n",
            " - 0s - loss: 0.3084 - acc: 0.8846 - val_loss: 1.9414 - val_acc: 0.5270\n",
            "Epoch 369/1000\n",
            " - 0s - loss: 0.3216 - acc: 0.8795 - val_loss: 1.9362 - val_acc: 0.5302\n",
            "Epoch 370/1000\n",
            " - 0s - loss: 0.2973 - acc: 0.8912 - val_loss: 1.9596 - val_acc: 0.5124\n",
            "Epoch 371/1000\n",
            " - 0s - loss: 0.3213 - acc: 0.8743 - val_loss: 1.9312 - val_acc: 0.5426\n",
            "Epoch 372/1000\n",
            " - 0s - loss: 0.2983 - acc: 0.8849 - val_loss: 1.9270 - val_acc: 0.5324\n",
            "Epoch 373/1000\n",
            " - 0s - loss: 0.2976 - acc: 0.8917 - val_loss: 1.9220 - val_acc: 0.5264\n",
            "Epoch 374/1000\n",
            " - 0s - loss: 0.2907 - acc: 0.8923 - val_loss: 1.9786 - val_acc: 0.5340\n",
            "Epoch 375/1000\n",
            " - 0s - loss: 0.3081 - acc: 0.8858 - val_loss: 1.9538 - val_acc: 0.5216\n",
            "Epoch 376/1000\n",
            " - 0s - loss: 0.3195 - acc: 0.8822 - val_loss: 1.9409 - val_acc: 0.5324\n",
            "Epoch 377/1000\n",
            " - 0s - loss: 0.3150 - acc: 0.8732 - val_loss: 1.9514 - val_acc: 0.5302\n",
            "Epoch 378/1000\n",
            " - 0s - loss: 0.2937 - acc: 0.8901 - val_loss: 2.0108 - val_acc: 0.5232\n",
            "Epoch 379/1000\n",
            " - 0s - loss: 0.3078 - acc: 0.8820 - val_loss: 1.9662 - val_acc: 0.5248\n",
            "Epoch 380/1000\n",
            " - 0s - loss: 0.3041 - acc: 0.8851 - val_loss: 1.9638 - val_acc: 0.5291\n",
            "Epoch 381/1000\n",
            " - 0s - loss: 0.2805 - acc: 0.8917 - val_loss: 2.0637 - val_acc: 0.5280\n",
            "Epoch 382/1000\n",
            " - 0s - loss: 0.3110 - acc: 0.8835 - val_loss: 2.0164 - val_acc: 0.5194\n",
            "Epoch 383/1000\n",
            " - 0s - loss: 0.2997 - acc: 0.8896 - val_loss: 1.9790 - val_acc: 0.5275\n",
            "Epoch 384/1000\n",
            " - 0s - loss: 0.2775 - acc: 0.8950 - val_loss: 2.0207 - val_acc: 0.5302\n",
            "Epoch 385/1000\n",
            " - 0s - loss: 0.3041 - acc: 0.8876 - val_loss: 2.0169 - val_acc: 0.5248\n",
            "Epoch 386/1000\n",
            " - 0s - loss: 0.2885 - acc: 0.8943 - val_loss: 2.0268 - val_acc: 0.5291\n",
            "Epoch 387/1000\n",
            " - 0s - loss: 0.3013 - acc: 0.8864 - val_loss: 2.0173 - val_acc: 0.5221\n",
            "Epoch 388/1000\n",
            " - 0s - loss: 0.2745 - acc: 0.8997 - val_loss: 2.0258 - val_acc: 0.5318\n",
            "Epoch 389/1000\n",
            " - 0s - loss: 0.2722 - acc: 0.8995 - val_loss: 2.0321 - val_acc: 0.5248\n",
            "Epoch 390/1000\n",
            " - 0s - loss: 0.2878 - acc: 0.8948 - val_loss: 2.0541 - val_acc: 0.5124\n",
            "Epoch 391/1000\n",
            " - 0s - loss: 0.2931 - acc: 0.8889 - val_loss: 2.0253 - val_acc: 0.5324\n",
            "Epoch 392/1000\n",
            " - 0s - loss: 0.2671 - acc: 0.8948 - val_loss: 2.0548 - val_acc: 0.5313\n",
            "Epoch 393/1000\n",
            " - 0s - loss: 0.2764 - acc: 0.8966 - val_loss: 2.0652 - val_acc: 0.5264\n",
            "Epoch 394/1000\n",
            " - 0s - loss: 0.2715 - acc: 0.8989 - val_loss: 2.0362 - val_acc: 0.5410\n",
            "Epoch 395/1000\n",
            " - 0s - loss: 0.2627 - acc: 0.9060 - val_loss: 2.0234 - val_acc: 0.5351\n",
            "Epoch 396/1000\n",
            " - 0s - loss: 0.2563 - acc: 0.9022 - val_loss: 2.0650 - val_acc: 0.5254\n",
            "Epoch 397/1000\n",
            " - 0s - loss: 0.2593 - acc: 0.9103 - val_loss: 2.0676 - val_acc: 0.5340\n",
            "Epoch 398/1000\n",
            " - 0s - loss: 0.2525 - acc: 0.9074 - val_loss: 2.0546 - val_acc: 0.5426\n",
            "Epoch 399/1000\n",
            " - 0s - loss: 0.2525 - acc: 0.9081 - val_loss: 2.0723 - val_acc: 0.5383\n",
            "Epoch 400/1000\n",
            " - 0s - loss: 0.2577 - acc: 0.9049 - val_loss: 2.1190 - val_acc: 0.5421\n",
            "Epoch 401/1000\n",
            " - 0s - loss: 0.2553 - acc: 0.9042 - val_loss: 2.1035 - val_acc: 0.5264\n",
            "Epoch 402/1000\n",
            " - 0s - loss: 0.2535 - acc: 0.9067 - val_loss: 2.0882 - val_acc: 0.5275\n",
            "Epoch 403/1000\n",
            " - 0s - loss: 0.2554 - acc: 0.9045 - val_loss: 2.1171 - val_acc: 0.5324\n",
            "Epoch 404/1000\n",
            " - 0s - loss: 0.2512 - acc: 0.9074 - val_loss: 2.1621 - val_acc: 0.5254\n",
            "Epoch 405/1000\n",
            " - 0s - loss: 0.2496 - acc: 0.9045 - val_loss: 2.1000 - val_acc: 0.5270\n",
            "Epoch 406/1000\n",
            " - 0s - loss: 0.2344 - acc: 0.9140 - val_loss: 2.1017 - val_acc: 0.5313\n",
            "Epoch 407/1000\n",
            " - 0s - loss: 0.2567 - acc: 0.9040 - val_loss: 2.1896 - val_acc: 0.5210\n",
            "Epoch 408/1000\n",
            " - 0s - loss: 0.2595 - acc: 0.9045 - val_loss: 2.1697 - val_acc: 0.5227\n",
            "Epoch 409/1000\n",
            " - 0s - loss: 0.2460 - acc: 0.9088 - val_loss: 2.1497 - val_acc: 0.5367\n",
            "Epoch 410/1000\n",
            " - 0s - loss: 0.2602 - acc: 0.9034 - val_loss: 2.1856 - val_acc: 0.5146\n",
            "Epoch 411/1000\n",
            " - 0s - loss: 0.2604 - acc: 0.9034 - val_loss: 2.2156 - val_acc: 0.5415\n",
            "1854/1854 [==============================] - 0s 76us/step\n",
            "0.5415318234710117\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}